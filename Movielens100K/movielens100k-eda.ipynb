{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed5be105",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-20T08:22:08.447510Z",
     "iopub.status.busy": "2024-11-20T08:22:08.447008Z",
     "iopub.status.idle": "2024-11-20T08:22:14.637349Z",
     "shell.execute_reply": "2024-11-20T08:22:14.635845Z"
    },
    "papermill": {
     "duration": 6.198875,
     "end_time": "2024-11-20T08:22:14.640311",
     "exception": false,
     "start_time": "2024-11-20T08:22:08.441436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd \n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SparseAdam,Adam,Adagrad,SGD\n",
    "#from livelossplot import PlotLosses\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00c25119",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T08:22:14.653041Z",
     "iopub.status.busy": "2024-11-20T08:22:14.652244Z",
     "iopub.status.idle": "2024-11-20T08:22:14.885140Z",
     "shell.execute_reply": "2024-11-20T08:22:14.883720Z"
    },
    "papermill": {
     "duration": 0.244072,
     "end_time": "2024-11-20T08:22:14.888805",
     "exception": false,
     "start_time": "2024-11-20T08:22:14.644733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "COLS = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "train_data = pd.read_csv(\"/kaggle/input/movielens-100k-dataset/ml-100k/u1.base\",sep='\\t', names=COLS).drop(columns=['timestamp']).astype(int)\n",
    "test_data = pd.read_csv(\"/kaggle/input/movielens-100k-dataset/ml-100k/u1.test\",sep='\\t', names=COLS).drop(columns=['timestamp']).astype(int)\n",
    "n_users, n_items = 1000,2000\n",
    "save_basepath = \"/kaggle/working/chkpt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b6e7d40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T08:22:14.899338Z",
     "iopub.status.busy": "2024-11-20T08:22:14.898790Z",
     "iopub.status.idle": "2024-11-20T08:22:14.921673Z",
     "shell.execute_reply": "2024-11-20T08:22:14.920350Z"
    },
    "papermill": {
     "duration": 0.030167,
     "end_time": "2024-11-20T08:22:14.924172",
     "exception": false,
     "start_time": "2024-11-20T08:22:14.894005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>943</td>\n",
       "      <td>1067</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>943</td>\n",
       "      <td>1074</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>943</td>\n",
       "      <td>1188</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>943</td>\n",
       "      <td>1228</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>943</td>\n",
       "      <td>1330</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating\n",
       "0            1         1       5\n",
       "1            1         2       3\n",
       "2            1         3       4\n",
       "3            1         4       3\n",
       "4            1         5       3\n",
       "...        ...       ...     ...\n",
       "79995      943      1067       2\n",
       "79996      943      1074       4\n",
       "79997      943      1188       3\n",
       "79998      943      1228       3\n",
       "79999      943      1330       3\n",
       "\n",
       "[80000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfd056fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T08:22:14.934292Z",
     "iopub.status.busy": "2024-11-20T08:22:14.932665Z",
     "iopub.status.idle": "2024-11-20T08:22:14.947073Z",
     "shell.execute_reply": "2024-11-20T08:22:14.945981Z"
    },
    "papermill": {
     "duration": 0.021899,
     "end_time": "2024-11-20T08:22:14.949507",
     "exception": false,
     "start_time": "2024-11-20T08:22:14.927608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1650"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.movie_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c457e291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T08:22:14.958551Z",
     "iopub.status.busy": "2024-11-20T08:22:14.958148Z",
     "iopub.status.idle": "2024-11-20T08:22:14.965523Z",
     "shell.execute_reply": "2024-11-20T08:22:14.964410Z"
    },
    "papermill": {
     "duration": 0.014647,
     "end_time": "2024-11-20T08:22:14.967877",
     "exception": false,
     "start_time": "2024-11-20T08:22:14.953230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Matrixfactorization(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_dim=20):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding( n_users, n_dim)\n",
    "        self.item_emb = nn.Embedding( n_items, n_dim)\n",
    "        self.user_emb.weight.data.uniform_(0, 0.05)\n",
    "        self.item_emb.weight.data.uniform_(0, 0.05)\n",
    "        \n",
    "    def forward(self, u, v):\n",
    "        # print(0, u, v)\n",
    "        u = self.user_emb(u)\n",
    "        v = self.item_emb(v)\n",
    "        # print(u.shape, v.shape)\n",
    "        out = (u*v).sum(1)   \n",
    "        # print(1, out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40f7b85b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T08:22:14.976744Z",
     "iopub.status.busy": "2024-11-20T08:22:14.976294Z",
     "iopub.status.idle": "2024-11-20T08:22:14.991926Z",
     "shell.execute_reply": "2024-11-20T08:22:14.990839Z"
    },
    "papermill": {
     "duration": 0.022778,
     "end_time": "2024-11-20T08:22:14.994334",
     "exception": false,
     "start_time": "2024-11-20T08:22:14.971556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epocs(model, train_data, test_data, epochs=10, lr=1e-3, wd=0.0, unsqueeze=False, patience = 5, early_stopping = False):\n",
    "    if not early_stopping:\n",
    "        print(f\"Early stopping not used\")\n",
    "    else:\n",
    "        print(f\"Early stopping used\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    avg = []\n",
    "    states = {}\n",
    "    history = {}\n",
    "    loss_list = []\n",
    "    chkpt_list = []\n",
    "    best_chkpt = None\n",
    "    best_loss = None\n",
    "    for i in tqdm(range(1, epochs+1)):\n",
    "        model.train()\n",
    "        for it in range(len(train_data)//BATCH_SIZE):\n",
    "            #---------------SETUP BATCH DATA-------------\n",
    "            df = train_data.sample(frac=BATCH_SIZE/len(train_data))\n",
    "            users = torch.LongTensor(df.user_id.values) # .cuda()\n",
    "            items = torch.LongTensor(df.movie_id.values) #.cuda()\n",
    "            ratings = torch.FloatTensor(df.rating.values) #.cuda()\n",
    "            if unsqueeze:\n",
    "                ratings = ratings.unsqueeze(1)\n",
    "            y_hat = model(users, items)\n",
    "            loss = F.mse_loss(y_hat, ratings)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg.append(loss.item())\n",
    "        print(f\"EPOCH {i} Train loss:\",sum(avg)/len(avg))\n",
    "        avg = []\n",
    "        state = model.state_dict()\n",
    "        states[i] = deepcopy(state)\n",
    "        # validation loss\n",
    "        val_loss = test_loss(model, test_data)\n",
    "        val_loss = round(val_loss, 3)\n",
    "        # perform early stopping\n",
    "        if early_stopping:\n",
    "            if not loss_list:\n",
    "                loss_list = [val_loss]\n",
    "                chkpt_list = [i]\n",
    "                best_chkpt = i\n",
    "                best_loss = val_loss\n",
    "                continue\n",
    "            if len(loss_list) == patience:\n",
    "                if min(loss_list) < val_loss:\n",
    "                    print(f\"Stopping early since loss didn't improve after {patience} epochs\")\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"loss improved!\")\n",
    "                    loss_list = [val_loss]\n",
    "                    chkpt_list = [i]\n",
    "                    best_chkpt = i\n",
    "                    best_loss = val_loss\n",
    "            else:\n",
    "                if min(loss_list) < val_loss:\n",
    "                    print(f\"loss didn't improve!\")\n",
    "                    loss_list = [val_loss] + loss_list\n",
    "                    chkpt_list = [i] + chkpt_list\n",
    "                else:\n",
    "                    print(f\"loss improved!\")\n",
    "                    loss_list = [val_loss]\n",
    "                    chkpt_list = [i]\n",
    "                    best_chkpt = i\n",
    "                    best_loss = val_loss\n",
    "    if best_chkpt is None:\n",
    "        best_chkpt = i\n",
    "        best_loss = val_loss\n",
    "    print(f\"Best loss achieved on {best_chkpt}/{epochs} epoch\")\n",
    "    return states[best_chkpt], best_chkpt, best_loss\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb544ca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T08:22:15.003289Z",
     "iopub.status.busy": "2024-11-20T08:22:15.002867Z",
     "iopub.status.idle": "2024-11-20T08:22:15.009344Z",
     "shell.execute_reply": "2024-11-20T08:22:15.008098Z"
    },
    "papermill": {
     "duration": 0.013426,
     "end_time": "2024-11-20T08:22:15.011523",
     "exception": false,
     "start_time": "2024-11-20T08:22:14.998097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_loss(model, test_data, unsqueeze=False):\n",
    "    model.eval()\n",
    "    users = torch.LongTensor(test_data.user_id.values) #.cuda()\n",
    "    items = torch.LongTensor(test_data.movie_id.values) #.cuda()\n",
    "    ratings = torch.FloatTensor(test_data.rating.values) #.cuda()\n",
    "    if unsqueeze:\n",
    "        ratings = ratings.unsqueeze(1)\n",
    "    y_hat = model(users, items)\n",
    "    loss = F.mse_loss(y_hat, ratings)\n",
    "    test_loss = loss.item()\n",
    "    print(\"test loss %.3f \" % test_loss)\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad0869bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T08:22:15.020245Z",
     "iopub.status.busy": "2024-11-20T08:22:15.019821Z",
     "iopub.status.idle": "2024-11-20T08:23:42.655628Z",
     "shell.execute_reply": "2024-11-20T08:23:42.654325Z"
    },
    "papermill": {
     "duration": 87.643539,
     "end_time": "2024-11-20T08:23:42.658584",
     "exception": false,
     "start_time": "2024-11-20T08:22:15.015045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrixfactorization(\n",
      "  (user_emb): Embedding(1000, 20)\n",
      "  (item_emb): Embedding(2000, 20)\n",
      ")\n",
      "Early stopping used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 1/20 [00:08<02:50,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 Train loss: 105.10709141025544\n",
      "test loss 65.351 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 2/20 [00:17<02:35,  8.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2 Train loss: 84.60182070960998\n",
      "test loss 74.495 \n",
      "loss didn't improve!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 3/20 [00:26<02:27,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3 Train loss: 92.72024394569397\n",
      "test loss 68.143 \n",
      "loss didn't improve!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 4/20 [00:34<02:18,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4 Train loss: 82.43661908683777\n",
      "test loss 73.686 \n",
      "loss didn't improve!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:43<02:09,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 5 Train loss: 94.25449419212342\n",
      "test loss 64.632 \n",
      "loss improved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:51<02:00,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 6 Train loss: 86.77570248374938\n",
      "test loss 69.556 \n",
      "loss didn't improve!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [01:00<01:51,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 7 Train loss: 93.29368261795044\n",
      "test loss 68.035 \n",
      "loss didn't improve!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:09<01:43,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 8 Train loss: 85.06658935890198\n",
      "test loss 70.109 \n",
      "loss didn't improve!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:17<01:34,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 9 Train loss: 88.21413794174194\n",
      "test loss 77.406 \n",
      "loss didn't improve!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:26<01:45,  9.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 10 Train loss: 89.20692593154907\n",
      "test loss 70.453 \n",
      "Stopping early since loss didn't improve after 5 epochs\n",
      "Best loss achieved on 5/20 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "model = Matrixfactorization(n_users,n_items)\n",
    "print(model)\n",
    "chkpt, best_chkpt_index, best_loss = train_epocs(model, train_data, test_data, epochs=20, lr=0.1, patience = 5, early_stopping = True)\n",
    "save_path = save_basepath + f'mf/' \n",
    "Path(save_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3975cd6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T08:23:42.670453Z",
     "iopub.status.busy": "2024-11-20T08:23:42.669823Z",
     "iopub.status.idle": "2024-11-20T08:23:42.676797Z",
     "shell.execute_reply": "2024-11-20T08:23:42.675676Z"
    },
    "papermill": {
     "duration": 0.015448,
     "end_time": "2024-11-20T08:23:42.679086",
     "exception": false,
     "start_time": "2024-11-20T08:23:42.663638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saving chkpts\n",
    "chkpt_path = save_path + f'{best_chkpt_index}_{best_loss}.chkpt'\n",
    "torch.save(chkpt, chkpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1cc5234",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T08:23:42.691791Z",
     "iopub.status.busy": "2024-11-20T08:23:42.691389Z",
     "iopub.status.idle": "2024-11-20T08:23:42.705257Z",
     "shell.execute_reply": "2024-11-20T08:23:42.704027Z"
    },
    "papermill": {
     "duration": 0.021935,
     "end_time": "2024-11-20T08:23:42.707241",
     "exception": false,
     "start_time": "2024-11-20T08:23:42.685306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 64.632 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64.63159942626953"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading chkpt\n",
    "model2 = Matrixfactorization(n_users,n_items)\n",
    "model2.load_state_dict(torch.load(chkpt_path, weights_only=True))\n",
    "test_loss(model2, test_data, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25090537",
   "metadata": {
    "papermill": {
     "duration": 0.004574,
     "end_time": "2024-11-20T08:23:42.716793",
     "exception": false,
     "start_time": "2024-11-20T08:23:42.712219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 626,
     "sourceId": 1187,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 98.311119,
   "end_time": "2024-11-20T08:23:44.046983",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-20T08:22:05.735864",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
